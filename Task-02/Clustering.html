<!DOCTYPE html>
<html>
<head>
<title>Clustering.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="k-means-clustering">K-Means Clustering</h1>
<p><strong>Target</strong> To understand the K-Means clustering and ways to find the best value of k.</p>
<h1 id=""></h1>
<hr>
<h2 id="what-is-k-means-clustering">What is K-Means Clustering</h2>
<p>Let's say someone asks you to show all toys you use to play or their equipment and you start showing it</p>
<p>Let's say you are out somewhere at any destination with your complete family. Your father asks &quot;who wants to eat strawberry ice cream</p>
<p>In a bucket, you have a different color of marble and you want to put similar marble in one bucket and another bucket. So you start separating them based on their size, color, and other parameters. Now you have 5 different buckets of marble and each bucket contains similar to marble.
So, the buckets are known as clusters and the process of separation and creating buckets is known as clustering.</p>
<p>In our case, we have 5 buckets that are <code>k=5</code>.</p>
<p>K-means clustering is an Unsupervised machine learning algorithm.</p>
<p><strong>Definition</strong> Clustering is a process of separating the data points into a number of clusters (groups), in such a way that data points in the same cluster are more similar to other data points in the same group and dissimilar to another cluster (groups).</p>
<h2 id="how-k-means-clustering-works">How K-Means Clustering works??</h2>
<ul>
<li>
<ol>
<li>It picks any random points(k points) from data as cluster center, that points also known as <strong>Centroids</strong>.</li>
</ol>
</li>
<li>
<ol start="2">
<li>Start assigning each data point to the nearest centroid.</li>
</ol>
</li>
<li>
<ol start="3">
<li>Recalculate the centroid of each cluster based on the mean of the data points assigned to it.</li>
</ol>
</li>
<li>
<ol start="4">
<li>Repeat steps 2 and 3 until the cluster assignment no longer changes or a maximum number of iterations is reached.</li>
</ol>
</li>
</ul>
<p>As Centroind move, the calculation of <strong>Squared Euclidean Distance</strong> is used to measure the similarity between the sample points and centroids.</p>
<h2 id="ways-to-find-the-best-value-for-k">Ways to find the Best value for K</h2>
<p>There are two main methods for calculating the optimal value of K(optimal number of clusters).</p>
<h3 id="elbow-curve-method">Elbow Curve Method</h3>
<ul>
<li>
<p>It is a graphical technique for determining the optimal number of clusters in a dataset.</p>
</li>
<li>
<p>working of method: as the number of clusters increases, the sum of the squared distance between the data points and their assigned cluster centroids(aka within-cluster sum of square or inertia) decreases, since each cluster is more specialized and compact.</p>
</li>
<li>
<ol>
<li>Initialize the value of k(number of the cluster). A good range for k is from 10 to 0.</li>
</ol>
</li>
<li>
<ol start="2">
<li>Now compute the <strong>within-cluster sum of the square(aka inertia)</strong>. A within-cluster sum of squares is defined as the <code>sum of squared distances between each data point and its assigned cluster centroid</code>. This measure the compactness of the cluster.</li>
</ol>
</li>
<li>
<ol start="3">
<li>Plot the within-cluster sum of the square as a function of a number of clusters (k).</li>
</ol>
</li>
<li>
<ol start="4">
<li>Identify the elbow point visually, the value of K at which the rate of decrease in the within-cluster sum of square start level-off.</li>
</ol>
</li>
<li>
<ol start="5">
<li>Now choose the optimal number of clusters based on the elbow point.</li>
</ol>
</li>
</ul>
<p>code</p>
<pre class="hljs"><code><div>x = iris_df.iloc[:, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]].values

<span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans
wcss = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>):
    kmeans = KMeans(n_clusters = i, init = <span class="hljs-string">'k-means++'</span>, 
                    max_iter = <span class="hljs-number">300</span>, n_init = <span class="hljs-number">10</span>, random_state = <span class="hljs-number">0</span>)
    kmeans.fit(x)
    wcss.append(kmeans.inertia_)

plt.plot(range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>), wcss)
plt.title(<span class="hljs-string">'The elbow method'</span>)
plt.xlabel(<span class="hljs-string">'Number of clusters'</span>)
plt.ylabel(<span class="hljs-string">'WCSS'</span>) <span class="hljs-comment"># Within cluster sum of squares</span>
plt.show()
</div></code></pre>

</body>
</html>
